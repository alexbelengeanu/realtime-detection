{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3b6cefc-bd5b-46ad-9fda-142341d8d9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcbaa78d-5f20-4c99-9d3c-1ab8fb6076c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fb37c3f-3fff-4f47-bdef-5f441496e182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection import maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights\n",
    "\n",
    "weights = MaskRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "model = maskrcnn_resnet50_fpn(weights=weights, progress=False).to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cdd2e1a-18cf-482a-919d-376b3cf0d4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# incarc toate clasele din datasetul pe care a fost antrenat modelul\n",
    "labels = open(\"coco.names.txt\").read().strip().split(\"\\n\")\n",
    "# generez o culoare pentru fiecare clasa in parte\n",
    "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa57324f-8b7d-4b5e-8799-5368b1b679cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = Image.open(\"image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cf9889f-e3df-4b0f-be73-46dd1b182810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms = weights.transforms()\n",
    "image = transforms(image)\n",
    "image=image.unsqueeze(0)\n",
    "image = image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5209c33a-c1fc-4818-8c9b-996a16814e62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "dict_keys(['boxes', 'labels', 'scores', 'masks'])\n"
     ]
    }
   ],
   "source": [
    "output = model(image) # list of dict\n",
    "print(len(output)) # equals to how many images that were fed into the model\n",
    "print(output[0].keys()) # dict_keys(['boxes', 'labels', 'scores', 'masks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eaa08ddd-f028-412d-8d00-7d0afef40c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source = np.asarray(Image.open(\"image.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f4ce1ff-8c1f-496b-b616-bd3ebcfb0613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, score in enumerate(output[0]['scores']):\n",
    "    if score > 0.5:\n",
    "        source = cv2.rectangle(source, \n",
    "                               (int(output[0]['boxes'][index][0]), int(output[0]['boxes'][index][1])), \n",
    "                               (int(output[0]['boxes'][index][2]), int(output[0]['boxes'][index][3])),\n",
    "                               (int(colors[int(output[0]['labels'][index])][0]), int(colors[int(output[0]['labels'][index])][1]), int(colors[int(output[0]['labels'][index])][2])),\n",
    "                               1)\n",
    "        source = cv2.putText(source, \n",
    "                             labels[int(output[0]['labels'][index])-1], \n",
    "                             (int(output[0]['boxes'][index][0]), int(output[0]['boxes'][index][1])-5), \n",
    "                             cv2.FONT_HERSHEY_SIMPLEX , \n",
    "                             .5, \n",
    "                             (int(colors[int(output[0]['labels'][index])][0]), int(colors[int(output[0]['labels'][index])][1]), int(colors[int(output[0]['labels'][index])][2])), \n",
    "                             1, \n",
    "                             cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3cef0e7b-f110-4c9b-83bc-4ecef7100abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(source).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30cbe70b-9c26-4b45-85ea-f720ecfe5afb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([352.9514, 171.5572, 422.1796, 367.7985], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]['boxes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc19b52-b49d-47d2-8b22-d9e14e771313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
